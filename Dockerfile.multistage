# Stage 1 - Base setup with system dependencies
FROM python:3.10.11-bullseye as base

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Install essential dependencies and git-lfs for model downloading
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    libhdf5-dev \
    libopenblas-dev \
    libomp-dev \
    cmake \
    libcurl4-openssl-dev \
    libssl-dev \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && pip install --upgrade pip

# Install Git LFS for downloading large files from Hugging Face repositories
RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash \
    && apt-get install -y git-lfs \
    && git lfs install

# Download wait-for-it.sh script using curl
RUN curl -o /wait-for-it.sh https://raw.githubusercontent.com/vishnubob/wait-for-it/master/wait-for-it.sh && \
    chmod +x /wait-for-it.sh

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --no-deps -r requirements.txt
RUN pip install packaging==20.9
RUN pip install tensorflow 
RUN pip install torch==2.4.1 torchvision==0.19.1+cpu torchaudio==2.4.1+cpu --index-url https://download.pytorch.org/whl/cpu

# Stage 2 - Download models and prepare data
FROM base as model-data-stage

# Download Hugging Face models directly into the specified directories
RUN mkdir -p /app/models/flan-t5-large && \
    git clone https://huggingface.co/google/flan-t5-large /app/models/flan-t5-large && \
    mkdir -p /app/models/embedding_models && \
    git clone https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 /app/models/embedding_models

# Copy scripts for downloading, preprocessing data, and training models
COPY scripts /app/scripts

# Download and preprocess Kaggle data
# RUN python /app/scripts/download_data.py && \
#     python /app/scripts/preprocess_data.py
RUN git clone https://github.com/pandeybk/unsw-nb15-dataset.git /app/data/


# Train predictive and Rasa models
RUN python /app/scripts/train_predictive_model.py --config_file /app/config.yaml && \
    rasa train --config /app/rasa/config.yml --domain /app/rasa/domain.yml --data /app/rasa/data --out /app/models/rasa

# Stage 3 - Final image
FROM base

# Copy only the necessary application files, trained models, and processed data
COPY --from=model-data-stage /app/models /app/models
COPY --from=model-data-stage /app/data/processed /app/data/processed
COPY . .

# Set environment path and entrypoint
ENV PYTHONPATH=/app
ENTRYPOINT ["./entrypoint.sh"]
CMD ["python", "app/run.py"]
